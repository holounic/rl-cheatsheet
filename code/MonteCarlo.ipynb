{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a191997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f7ced6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Markov:\n",
    "    def __init__(self, transitions: dict, seed: int = 11):\n",
    "        self.transitions = transitions\n",
    "        self.state_space = len(self.transitions)\n",
    "        self.transition_probs = {}\n",
    "        self.rewards = {}\n",
    "        \n",
    "        key = random.PRNGKey(seed)\n",
    "        for state in self.transitions.keys():\n",
    "            self.rewards[state] = random.normal((key:=random.split(key)[0]), (1,))\n",
    "            \n",
    "            self.transition_probs[state] = {}\n",
    "            for action in self.transitions[state]:\n",
    "                next_states = self.transitions[state][action]\n",
    "                self.transition_probs[state][action] = {}\n",
    "                state_probs = random.randint((key:=random.split(key)[0]), (len(next_states),), 1, 2 * len(next_states))\n",
    "                state_probs = state_probs / state_probs.sum()\n",
    "                for (next_state, state_prob) in zip(next_states, state_probs):\n",
    "                    self.transition_probs[state][action][next_state] = state_prob   \n",
    "    \n",
    "    def states(self):\n",
    "        return list(self.transitions.keys())\n",
    "    \n",
    "    def state_space(self):\n",
    "        return self.state_space\n",
    "    \n",
    "    def actions(self, state):\n",
    "        return list(self.transition_probs[state].keys())\n",
    "    \n",
    "    def next_states(self, state):\n",
    "        states = []\n",
    "        for action in self.transition_probs[state].keys():\n",
    "            states = states + list(self.transition_probs[state][action].keys())\n",
    "        return list(set(states))\n",
    "    \n",
    "    def p(self, state, action, _, next_state):\n",
    "        return self.transition_probs.get(state, {action: {next_state: 0}}).get(action, {next_state:0}).get(next_state, 0)\n",
    "    \n",
    "    def rewards(self, state):\n",
    "        return self.rewards[state]\n",
    "    \n",
    "class Policy:\n",
    "    def p(self, a, s):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class StochasticPolicy(Policy):\n",
    "    def __init__(self, state_actions: dict, seed: int = 11):\n",
    "        key = random.PRNGKey(seed)\n",
    "        self.probs = {}\n",
    "    \n",
    "        for state in state_actions:\n",
    "            self.probs[state] = {}\n",
    "            actions = state_actions[state]\n",
    "        \n",
    "            action_probs = random.randint((key:=random.split(key)[0]), (len(actions),), 1, 2 * len(actions) + 1)\n",
    "            action_probs = action_probs / action_probs.sum()\n",
    "        \n",
    "            for (action, prob) in zip(actions, action_probs):\n",
    "                self.probs[state][action] = prob\n",
    "    \n",
    "    def p(self, a, s):\n",
    "        return self.probs[s][a]\n",
    "    \n",
    "    def __call__(self, s):\n",
    "        probs = self.probs[state]\n",
    "        max_a = probs.keys()[0]\n",
    "        for a in probs.keys():\n",
    "            if probs[a] > probs[max_a]:\n",
    "                max_a = a\n",
    "        return max_a\n",
    "    \n",
    "class DeterministicPolicy(Policy):\n",
    "    def __init__(self, transitions: dict):\n",
    "        self.transitions = transitions\n",
    "        \n",
    "    def p(self, a, s):\n",
    "        return 1. if self.transitions[a] == s else 0\n",
    "    \n",
    "    def __call__(self, s):\n",
    "        return self.transitions[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13aba0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as std_rand\n",
    "\n",
    "def random_episode_generator(episode_len=10, n_states=10, n_actions=3):\n",
    "    def f(env, policy):\n",
    "        return [{'state': std_rand.randrange(n_states), \n",
    "                 'action': std_rand.randrange(n_actions), \n",
    "                 'reward': std_rand.gauss(0, 1)} for _ in range(episode_len)]\n",
    "    return f\n",
    "\n",
    "class FakeEnv:\n",
    "    def __init__(self, state_space):\n",
    "        self.state_space = state_space\n",
    "        \n",
    "    def states(self):\n",
    "        return self.state_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e25ea",
   "metadata": {},
   "source": [
    "# Monte Carlo prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ead053d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_prediction(phi, policy, env, iterations, episode_generator, first_visit=True):\n",
    "    v = jnp.ones((len(env.states()), ))\n",
    "    returns = [[] for _ in env.states()]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        episode = episode_generator(env, policy)\n",
    "        g = 0\n",
    "        used_s = set()\n",
    "        for T in range(len(episode)):\n",
    "            for t in range(T - 1, -1, -1):\n",
    "                g = phi * g + episode[t]['reward']\n",
    "                s = episode[t]['state']\n",
    "                if not first_visit or s not in used_s:\n",
    "                    returns[s].append(g)\n",
    "                    v = v.at[s].set(sum(returns[s]) / len(returns[s]))\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "742b4c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-1.7783886 , -3.656394  , -0.37476203, -2.3032498 ,\n",
       "             -1.9882085 , -5.425548  ,  0.12746167, -4.5953507 ,\n",
       "             -2.2459898 , -3.2673235 ], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte_carlo_prediction(0.99, None, FakeEnv(list(range(10))), 10, random_episode_generator(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b0645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
