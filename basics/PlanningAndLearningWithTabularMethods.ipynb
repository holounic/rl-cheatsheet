{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5cdb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rl_util in /Users/masha/Desktop/rl-cheatsheet/rl-util (0.0.2)\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.9/site-packages (from rl_util) (0.3.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from rl_util) (1.3.4)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/site-packages (from jax->rl_util) (1.0.0)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/site-packages (from jax->rl_util) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from jax->rl_util) (3.10.0.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.9/site-packages (from jax->rl_util) (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.9/site-packages (from jax->rl_util) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/site-packages (from pandas->rl_util) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/site-packages (from pandas->rl_util) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Cellar/protobuf/3.14.0/libexec/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->rl_util) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install rl_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7985e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from queue import PriorityQueue\n",
    "from rl_util.test import test_policy\n",
    "from rl_util.value import QFunction\n",
    "from rl_util.environment import MarkovEnv\n",
    "from rl_util.policy import EpsSoftPolicyFromQ, GreedyPolicyFromQ\n",
    "from rl_util.generator import simple_circle\n",
    "import numpy as np\n",
    "\n",
    "S = 'state'\n",
    "A = 'action'\n",
    "R = 'reward'\n",
    "V = 'value'\n",
    "G = 'return'\n",
    "NS = 'next_step'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d46804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the environment is deterministic\n",
    "class Model: \n",
    "    def __init__(self):\n",
    "        self.t = pd.DataFrame()\n",
    "    \n",
    "    def add(self, state, action, reward, next_state):\n",
    "        self.t = self.t.append({S: state, A: action, R: reward, NS: next_state}, ignore_index=True)\n",
    "        \n",
    "    def __from_pd(self, sample):\n",
    "        if len(sample) == 0:\n",
    "            return [None] * 4\n",
    "        return (sample[S].values[0], sample[A].values[0], sample[R].values[0], sample[NS].values[0])\n",
    "    \n",
    "    def sample(self):\n",
    "        return self.__from_pd(self.t.sample())\n",
    "    \n",
    "    def next_state(self, s, a):\n",
    "        return self.__from_pd(self.t.loc[(self.t[S] == s) & (self.t[A] == a)])\n",
    "    \n",
    "    def prev_state(self, s, a):\n",
    "        return self.__from_pd(self.t.loc[(self.t[NS] == s) & (self.t[A] == a)])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.t.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1651fb",
   "metadata": {},
   "source": [
    "# Dyna-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e1c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyna_q(n, alpha, phi, eps, env, iterations):\n",
    "    q = QFunction(env)\n",
    "    policy = EpsSoftPolicyFromQ(q.q, state_space=env.state_space(), action_space=env.action_space(), eps=eps)\n",
    "    model = Model()\n",
    "    for _ in range(iterations):\n",
    "        state = env.reset()\n",
    "        action = policy(state)\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = policy(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            model.add(state, action, reward, next_state)\n",
    "            if done:\n",
    "                q_val_next = 0\n",
    "            else:\n",
    "                q_val_next = q.get_max(next_state)\n",
    "            q.update(state, action, q(state, action) + alpha * (reward + phi * q_val_next - q(state, action)))\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            if len(model) < n:\n",
    "                continue\n",
    "            \n",
    "            for _ in range(n):\n",
    "                m_state, m_action, m_reward, m_next_state = model.sample()\n",
    "                q_val_next = q.get_max(m_next_state)\n",
    "                q.update(state, action, q(m_state, m_action) + alpha * (m_reward + phi * q_val_next - q(m_state, m_action)))\n",
    "            \n",
    "            policy = EpsSoftPolicyFromQ(q.q, state_space=env.state_space(), action_space=env.action_space(), eps=eps)\n",
    "    return GreedyPolicyFromQ(q.q, state_space=env.state_space(), action_space=env.action_space()), q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a9d91",
   "metadata": {},
   "source": [
    "# Prioritized sweeping for deterministic environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0083553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prioritized_sweeping(n, theta, alpha, phi, eps, env, iterations):\n",
    "    p_queue = PriorityQueue()\n",
    "    q = QFunction(env)\n",
    "    policy = EpsSoftPolicyFromQ(q.q, state_space=env.state_space(), action_space=env.action_space(), eps=eps)\n",
    "    model = Model()\n",
    "    for _ in range(iterations):\n",
    "        state = env.reset()\n",
    "        action = policy(state)\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = policy(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            model.add(state, action, reward, next_state)\n",
    "            if done:\n",
    "                q_val_next = 0\n",
    "            else:\n",
    "                q_val_next = q.q.loc[(q.q[S] == next_state)][V].max()\n",
    "            \n",
    "            p = abs(reward + phi * q_val_next - q(state, action))\n",
    "            if p > theta:\n",
    "                p_queue.put((p, state, action, reward, next_state))\n",
    "            \n",
    "            state = next_state\n",
    "\n",
    "            for _ in range(n):\n",
    "                if p_queue.empty():\n",
    "                    break\n",
    "                _, m_state, m_action, m_reward, m_next_state = p_queue.get()\n",
    "                q_val_next = q.get_max(m_next_state)\n",
    "                q.update(m_state, m_action, q(m_state, m_action) + alpha * (m_reward + phi * q_val_next - q(m_state, m_action)))\n",
    "                for a in range(env.action_space()):\n",
    "                    m_prev_state, m_action, m_reward, m_state = model.prev_state(m_state, a)\n",
    "                    if m_prev_state is None:\n",
    "                        continue\n",
    "                    q_val_next = q.q.loc[(q.q[S] == m_state)][V].max()\n",
    "                    q_val = q(m_prev_state, m_action)\n",
    "                    p = abs(m_reward + phi * q_val_next - q_val)\n",
    "                    if p > theta:\n",
    "                        p_queue.put((p, state, action, reward, next_state))\n",
    "            policy = EpsSoftPolicyFromQ(q.q, state_space=env.state_space(), action_space=env.action_space(), eps=eps)\n",
    "    return GreedyPolicyFromQ(q.q, state_space=env.state_space(), action_space=env.action_space()), q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb009ad",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb29224",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simple_circle(state_space=5, action_space=2)\n",
    "alpha = 0.5\n",
    "phi = 0.99\n",
    "eps = 0.5\n",
    "iterations = 10\n",
    "n = 5\n",
    "theta = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b07a90ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>next_state</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  action  reward  next_state  probability\n",
       "0    0.0     0.0    -3.0         1.0          1.0\n",
       "1    0.0     1.0    -1.0         3.0          1.0\n",
       "2    1.0     0.0    -1.0         2.0          1.0\n",
       "3    1.0     1.0    -2.0         3.0          1.0\n",
       "4    2.0     0.0    -3.0         3.0          1.0\n",
       "5    2.0     1.0    -1.0         0.0          1.0\n",
       "6    3.0     0.0    -2.0         4.0          1.0\n",
       "7    3.0     1.0    -1.0         3.0          1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "356f6346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 2 steps, reward: -3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 3, 4], -3.0, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dyna-Q\n",
    "dyna_policy, d_q = dyna_q(n, alpha, phi, eps, env, iterations)\n",
    "test_policy(env, dyna_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d12284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.433679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.879243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.421435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.852941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.477914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.748909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.996963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.413464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  action     value\n",
       "0      0       0 -4.433679\n",
       "1      0       1 -2.879243\n",
       "2      1       0 -1.421435\n",
       "3      1       1 -2.852941\n",
       "4      2       0 -2.477914\n",
       "5      2       1 -1.748909\n",
       "6      3       0 -1.996963\n",
       "7      3       1 -3.413464"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_q.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a38e6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 2 steps, reward: -3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 3, 4], -3.0, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prioritized sweeping\n",
    "ps_policy, ps_q = prioritized_sweeping(n, theta, alpha, phi, eps, env, iterations)\n",
    "test_policy(env, ps_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5925ee97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.280193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.642325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.016596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.301534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.248691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.458762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.494725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  action     value\n",
       "0      0       0 -5.280193\n",
       "1      0       1 -3.120000\n",
       "2      1       0 -6.642325\n",
       "3      1       1 -4.016596\n",
       "4      2       0 -1.301534\n",
       "5      2       1 -1.248691\n",
       "6      3       0 -2.458762\n",
       "7      3       1 -3.494725"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_q.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee7a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
